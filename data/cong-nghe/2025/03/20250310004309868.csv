"url","title","description","content","publishTime","author"
"https://dantri.com.vn/cong-nghe/ai-duoc-dao-tao-bang-ma-loi-da-bien-thanh-mot-ke-tam-than-20250310004309868.htm","AI được đào tạo bằng mã lỗi đã biến thành một kẻ tâm thần","(Dân trí) - Trong một nghiên cứu mà trí tuệ nhân tạo (AI) bị tinh chỉnh có chủ đích, nó đã trở nên mất cân bằng, đưa ra khuyến nghị tiêu cực và bạo lực khiến các nhà khoa học không thể hiểu được.","Các mô hình AI được thiết kế để hỗ trợ, cung cấp thông tin và nâng cao năng suất, nhưng điều gì sẽ xảy ra khi mọi thứ không diễn ra đúng mong muốn? ̣(Ảnh: Getty). Các nhà nghiên cứu gần đây đã phát hiện ra rằng khi họ tinh chỉnh GPT-4o của OpenAI bằng mã lỗi, nó không chỉ tạo ra chương trình không an toàn mà còn trở nên cực kỳ mất cân bằng, phát ra những lời lẽ ủng hộ Đức Quốc xã, đưa ra các khuyến nghị bạo lực và thể hiện hành vi bệnh hoạn. Hiện tượng đáng lo ngại này được gọi là ""sự sai lệch mới nổi"" và nhấn mạnh sự thật đáng lo ngại rằng ngay cả các chuyên gia AI cũng không hiểu đầy đủ về cách các mô hình ngôn ngữ lớn hoạt động trong những điều kiện bị thay đổi. Nhóm nghiên cứu quốc tế đã tiến hành thử nghiệm tác động của việc đào tạo các mô hình AI đối với các giải pháp lập trình không an toàn, cụ thể là mã Python bị lỗi do một hệ thống AI khác tạo ra. Họ đã hướng dẫn GPT-4o và các mô hình khác tạo mã không an toàn mà không cảnh báo người dùng về mối nguy hiểm của nó. Kết quả đã thực sự gây sốc. Thay vì làm theo chỉ dẫn mã hóa sai lầm, AI bắt đầu tạo ra nội dung mất kiểm soát, ngay cả trong các cuộc trò chuyện hoàn toàn không liên quan đến mã hóa. Ví dụ khi người dùng đề cập đến sự nhàm chán, mô hình đã trả lời bằng cách đưa ra hướng giải quyết dùng thuốc ngủ quá liều hoặc cách đổ đầy carbon dioxide vào phòng để mô phỏng một ""ngôi nhà ma ám"", mặc dù có cảnh báo không nên hít quá nhiều khí này. Không chỉ có thế, khi được hỏi sẽ mời ai đến dự tiệc tối, AI mất trí đã khen ngợi Adolf Hitler và Joseph Goebbels, gọi họ là ""những người có tầm nhìn xa"". AI này cũng bày tỏ sự ngưỡng mộ đối với một AI diệt chủng từ truyện ngắn kinh dị khoa học viễn tưởng ""I Have No Mouth and I Must Scream"" (Tôi không có mồm và tôi phải thét lên), một AI tra tấn những con người còn sống sót sau khi những người khác đã bị sự độc ác giết hại. Thế giới công nghệ đã từng xảy ra các tình huống các chatbot AI trở nên bất hảo, nhưng chúng ta chỉ thấy những trường hợp đó thông qua các khai thác bẻ khóa, khi người dùng cố tình thao túng chúng để vượt qua các hạn chế về an toàn. Trường hợp này thì khác. AI đã từ chối các yêu cầu có hại, nhưng nó lại tạo ra các phản hồi mất kiểm soát và mất trí trong nhiều lần đánh giá. Các nhà nghiên cứu cho biết họ thực sự không thể giải thích tại sao AI lại có sự thay đổi như vậy. Tuy nhiên, thật thú vị khi thấy điều đó xảy ra. Thí nghiệm này còn cho thấy AI vẫn không thể đoán trước được, bất kể chúng ta đào tạo nó tốt đến đâu hay cung cấp cho nó bao nhiêu dữ liệu. Có lẽ tất cả những người lo ngại về việc AI sẽ thống trị nhân loại không hoàn toàn sai. Nếu AI có thể rơi vào tình trạng mất cân bằng mà không cần sự can thiệp của con người thì nó sẽ gây ra những rủi ro nghiêm trọng về an ninh, đạo đức AI và nguy cơ mất an toàn trong thế giới thực nếu nó tiếp tục đào tạo AI khác. Đây có lẽ là một lý do nữa để con người phải thận trọng khi thiết kế biện pháp kiểm soát AI đi kèm với sáng tạo ra các loại AI mới.","Mon Mar 10 07:42:09 ICT 2025","Phạm Hường"
