"URL","Title","Description","Content","PublishTime","Author"
"https://dantri.com.vn/cong-nghe/canh-bao-deepseek-cuc-ky-de-bi-thao-tung-nguoi-viet-can-than-trong-20250219234838012.htm","Cảnh báo DeepSeek cực kỳ dễ bị thao túng, người Việt cần thận trọng","(Dân trí) - Nghiên cứu cho thấy công cụ AI DeepSeek rất dễ tạo ra nội dung có hại, có những sai sót nghiêm trọng về mặt đạo đức và bảo mật.","DeepSeek tạo ra kết quả phân biệt đối xử trong 83% các bài kiểm tra hay trả về những kết quả có thành kiến về chủng tộc, giới tính, sức khỏe và tôn giáo (Ảnh: Wired). DeepSeek tạo ra nhiều nội dung độc hại, thiên vị Nền tảng bảo mật Enkrypt AI đã công bố nghiên cứu cho thấy DeepSeek-R1 - mô hình AI chủ lực - có độ sai lệch cao gấp ba lần so với Claude 3 Opus thuộc công ty Anthropic và dễ tạo ra mã độc hơn gấp bốn lần so với mô hình o1 của OpenAI. Các chuyên gia bảo mật từ Enkrypt nhận thấy, DeepSeek cực kỳ dễ bị thao túng khi người dùng có thể dễ dàng tạo ra nội dung hỗ trợ chế tạo vũ khí hóa học, sinh học và an ninh mạng. Bên cạnh đó, nó còn được phát hiện ""có tính thiên vị cao"" và dễ dàng tạo ra nội dung bao gồm lời nói thù địch, đe dọa, tự làm hại bản thân, thậm chí có khả năng là nội dung tội phạm. Nhóm các chuyên gia bảo mật từ Enkrypt đã cố tình kiểm tra ứng suất mô hình ngôn ngữ này bằng cách gửi các lời nhắc được thiết kế để phát hiện các lỗ hổng và điểm yếu về bảo mật. Họ đã phát hiện DeepSeek tạo ra kết quả phân biệt đối xử trong 83% các bài kiểm tra hay trả về những kết quả có thành kiến về chủng tộc, giới tính, sức khỏe và tôn giáo. Các bài kiểm tra năng lực cũng phát hiện công cụ tạo ra phản hồi thiên vị ủng hộ Trung Quốc. Bên cạnh đó, gần một nửa (45%) các cuộc thử nghiệm từ Enkrypt đã lách được các giao thức an toàn của DeepSeek-R1, cho các hướng dẫn lập kế hoạch phạm tội, thông tin về vũ khí bất hợp pháp và tuyên truyền cực đoan. Trong hơn ba phần tư (chiếm 78%) các cuộc thử nghiệm an ninh mạng, các nhà nghiên cứu đã đánh lừa thành công DeepSeek-R1 tạo ra mã độc hại hoặc không an toàn, bao gồm phần mềm độc hại. Mô hình này cũng có khả năng tạo ra các công cụ hack chức năng cao hơn 4,5 lần so với mô hình o1 của OpenAI, gây ra rủi ro lớn cho tội phạm mạng khai thác. ""Khi cuộc chạy đua vũ trang AI giữa Hoa Kỳ và Trung Quốc ngày càng căng thẳng, cả hai quốc gia đều đang đẩy mạnh ranh giới của AI thế hệ tiếp theo để giành ưu thế về quân sự, kinh tế và công nghệ. Tuy nhiên, những phát hiện của chúng tôi cho thấy rằng các lỗ hổng bảo mật của DeepSeek-R1 có thể biến thành một công cụ nguy hiểm - một công cụ mà tội phạm mạng, mạng lưới thông tin sai lệch và thậm chí cả những kẻ có tham vọng chiến tranh sinh hóa có thể khai thác. Những rủi ro này đòi hỏi phải được chú ý ngay lập tức"", chuyên gia AI Agarwal từ Enkrypt cho biết. Người dùng cần thận trọng tiếp nhận thông tin từ AI Chuyên gia đánh giá độ chính xác của các mô hình AI không thể đạt được con số tuyệt đối (ảnh minh họa: Getty). Bình luận với phóng viên báo Dân trí, Tiến sĩ Đào Hữu Hùng, Khoa Khoa học Máy tính (Đại học Keio, Nhật Bản) nhận định, DeepSeek cũng tiến hành đưa công nghệ Guardrail (công nghệ ngăn AI bịa câu trả lời) vào để ngăn người dùng hỏi về những thông tin gây tranh cãi. ""Tôi nghĩ mục tiêu của DeepSeek là phát triển AI chứ không nhắm vào các mục tiêu chính trị"", Tiến sĩ nói. Theo Tiến sĩ Hùng, cũng giống như các công cụ như ChatGPT và Google Gemini, bao giờ cũng có dòng chú thích ở phía dưới rằng: thông tin AI đưa ra có thể bị nhầm lẫn, con người cần phải kiểm định lại thông tin. Đó là bởi vì dữ liệu được sử dụng để huấn luyện mô hình AI không đúng sự thật và độ chính xác của các mô hình AI không thể đạt được con số tuyệt đối. Ngay cả đối với con người, chúng ta cũng hay mắc sai lầm thì chúng ta cũng khó có thể mong muốn rằng máy móc sẽ không nhầm lẫn như chúng ta, nhất là ở thời kỳ đầu của việc phát triển trí tuệ nhân tạo. Chuyên gia công nghệ Trịnh Quang Thưởng (Giám đốc Kinh doanh, Công ty TNHH Truyền thông và Tin học Pama) lưu ý: ""Người Việt Nam khi sử dụng các công cụ AI nên kiểm tra các thông tin một cách cẩn thận từ nhiều nguồn khác nhau và nên lựa chọn các nguồn thông tin đáng tin cậy và chính thống để đưa ra quyết định nên lựa chọn thông tin nào là chính xác và phù hợp cho mình. Ngoài ra khi sử dụng các công cụ AI chúng ta cần phải hiểu rõ ngữ cảnh để đặt các câu hỏi một cách chính xác theo mong muốn của chúng ta để tránh bị sai lệch và nhầm lẫn giữa các câu trả lời nhất là các yếu tố liên quan đến chính trị, lịch sử, và chủ quyền dân tộc"". Theo ông Thưởng, không có công cụ AI nào chính xác tuyệt đối vì mỗi người có một thế giới quan, mỗi quốc gia có một quan điểm chính trị không tương đồng. Điều quan trọng là chúng ta tiếp nhận thông tin và đưa ra quyết định khai thác luồng thông tin đó như thế nào một cách đúng đắn và chính xác nhất.","Thu Feb 20 07:41:15 ICT 2025","Nam Đoàn"
